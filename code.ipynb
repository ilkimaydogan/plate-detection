{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e885f0fe-4056-479b-bcbb-3f274b25fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import slic, mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bda17f-27f2-4e8a-af21-bf234418da10",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c5246-84eb-438d-a5c2-27504a429db8",
   "metadata": {},
   "source": [
    "#### Sobel Filter implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752a0a53-2a0d-404e-abf0-4ee94472b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(image):\n",
    "    #added dtype float64 to get a better result\n",
    "    x_kernel = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]], \n",
    "                        dtype=np.float64)\n",
    "    \n",
    "    y_kernel = np.array([[-1, -2, -1],\n",
    "                        [0, 0, 0],\n",
    "                        [1, 2, 1]], \n",
    "                        dtype=np.float64)\n",
    "    \n",
    "    image = image.astype(np.float64)\n",
    "    \n",
    "    x_gradient = ndimage.convolve(image, x_kernel)\n",
    "    y_gradient = ndimage.convolve(image, y_kernel)\n",
    "    \n",
    "    edges = np.sqrt(x_gradient**2 + y_gradient**2)\n",
    "    edges = edges / edges.max() * 255\n",
    "\n",
    "    theta_matrix  = np.arctan2(y_gradient, x_gradient)\n",
    "    \n",
    "    return edges, theta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03187857-655a-4a14-b2db-ff6b9d37ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(magnitude, direction):\n",
    "    height, width = magnitude.shape\n",
    "    non_max_matrix = np.zeros((height,width), dtype=np.int32)\n",
    "    angle = direction * 180. / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    \n",
    "    for i in range(1,height-1):\n",
    "        for j in range(1,width-1):\n",
    "            q = 255\n",
    "            r = 255\n",
    "\n",
    "           #angle 0\n",
    "            if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n",
    "                q = magnitude[i, j+1]\n",
    "                r = magnitude[i, j-1]\n",
    "            #angle 45\n",
    "            elif (22.5 <= angle[i,j] < 67.5):\n",
    "                q = magnitude[i+1, j-1]\n",
    "                r = magnitude[i-1, j+1]\n",
    "            #angle 90\n",
    "            elif (67.5 <= angle[i,j] < 112.5):\n",
    "                q = magnitude[i+1, j]\n",
    "                r = magnitude[i-1, j]\n",
    "            #angle 135\n",
    "            elif (112.5 <= angle[i,j] < 157.5):\n",
    "                q = magnitude[i-1, j-1]\n",
    "                r = magnitude[i+1, j+1]\n",
    "\n",
    "            if (magnitude[i,j] >= q) and (magnitude[i,j] >= r):\n",
    "                non_max_matrix[i,j] = magnitude[i,j]\n",
    "            else:\n",
    "                non_max_matrix[i,j] = 0\n",
    "\n",
    "    \n",
    "    return non_max_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d496682-5fcd-41b4-92db-2e2807b5b52e",
   "metadata": {},
   "source": [
    "#### Canny Edge implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4806a0-f62a-48a3-8b3a-92f1ef854d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(image,low_threshold=40, high_threshold=80):\n",
    "    height, width = image.shape\n",
    "    \n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    magnitude, directions = sobel_filter(blurred_image)\n",
    "    non_max = non_max_suppression(magnitude, directions)\n",
    "    \n",
    "    weak_value = 25\n",
    "    strong_value = 255\n",
    "    \n",
    "    link_matrix = non_max.copy()\n",
    "    link_matrix = np.where(non_max > high_threshold, strong_value, np.where(non_max > low_threshold, weak_value,0))\n",
    "\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            if(link_matrix[i,j] == weak_value):\n",
    "                if ((link_matrix[i+1, j-1] == strong_value) or \n",
    "                    (link_matrix[i+1, j] == strong_value) or \n",
    "                    (link_matrix[i+1, j+1] == strong_value) or \n",
    "                    (link_matrix[i, j-1] == strong_value) or \n",
    "                    (link_matrix[i, j+1] == strong_value) or \n",
    "                    (link_matrix[i-1, j-1] == strong_value) or \n",
    "                    (link_matrix[i-1, j] == strong_value) or \n",
    "                    (link_matrix[i-1, j+1] == strong_value)):\n",
    "                    link_matrix[i, j] = strong_value\n",
    "                else:\n",
    "                    link_matrix[i, j] = 0\n",
    "\n",
    "    return link_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2fda4-9abd-4612-848b-b3b447e18ac2",
   "metadata": {},
   "source": [
    "#### Hough Transform implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e1c1a5-2d8c-4d24-89e1-aa2157fb8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(edge_image, edge_threshold=200, line_threshold_min=100, theta_min=0, theta_max=180, num_of_lines=0, desc=True):\n",
    "    \n",
    "    # initializing accumulator space\n",
    "    # defining the ranges for parameters\n",
    "    rho_max = round(np.sqrt(edge_image.shape[1]**2 + edge_image.shape[0]**2)) # max distance from origin \n",
    "    rhos_size = 2 * rho_max + 1\n",
    "    # creating an array to store and iterate in thetas and rhos\n",
    "    thetas = np.deg2rad(np.arange(theta_min, theta_max))\n",
    "    rhos = np.arange(-rho_max, rho_max+1)\n",
    "    accumulator = np.zeros((rhos.shape[0],thetas.shape[0]))\n",
    "    \n",
    "    width, height = edge_image.shape\n",
    "    \n",
    "    # filling accumulator array\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            if edge_image[w][h] > edge_threshold:\n",
    "                for t in range(len(thetas)):\n",
    "                    cos_theta = np.cos(thetas[t])\n",
    "                    sin_theta = np.sin(thetas[t])\n",
    "                    rho = w * cos_theta + h * sin_theta\n",
    "                    for r in range(len(rhos)):\n",
    "                        if rhos[r] > rho:\n",
    "                            break    \n",
    "                    accumulator[r][t] += 1 \n",
    "\n",
    "    # padding the array for easier computation of local maximas\n",
    "    padded_array = cv2.copyMakeBorder(accumulator, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0) \n",
    "    local_maximas = []\n",
    "    # iterate through each element in the 2D array\n",
    "    for r in range(1, len(rhos)+1):\n",
    "        for t in range(1, len(thetas+1)):\n",
    "            if  padded_array[r,t] > line_threshold_min \\\n",
    "                and padded_array[r, t] > padded_array[r - 1, t] and padded_array[r, t] > padded_array[r + 1, t] \\\n",
    "                and padded_array[r, t] > padded_array[r, t - 1] and padded_array[r, t] > padded_array[r, t + 1]:\n",
    "                local_maximas.append((rhos[r-1], thetas[t-1], accumulator[r-1,t-1]))\n",
    "    # sorting the local maximas according to votes\n",
    "    sorted_maximas = sorted(local_maximas, key=lambda x: x[2],reverse=desc)\n",
    "    if num_of_lines != 0:\n",
    "        return sorted_maximas[:num_of_lines]\n",
    "    else:\n",
    "        return sorted_maximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a683e6a1-d913-4a2b-b0d3-2324b3c26920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_to_cartesian(rho, theta, weight = 500):\n",
    "    rho = np.float32(rho)\n",
    "    theta = np.float32(theta)\n",
    "    a = np.sin(theta)\n",
    "    b = np.cos(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    pt1 = (int(x0 + weight*(-b)), int(y0 + weight*(a)))\n",
    "    pt2 = (int(x0 - weight*(-b)), int(y0 - weight*(a)))\n",
    "    return pt1, pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69eece10-f92b-49f0-bea1-4fe0aee4df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hough_lines(lines, image):\n",
    "    for line in lines:\n",
    "        pt1, pt2 = hough_to_cartesian(line[0], line[1])\n",
    "        cv2.line(image, pt1, pt2, (0,0,255), 2, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f2368-06e3-47b7-998a-b434971c920b",
   "metadata": {},
   "source": [
    "## Detecting squares from hough lines\n",
    "After implementing every function needed for hough transformation to detect squares from these hough lines i implemented an approach similar to the article **Rectangle Detection based on a Windowed Hough Transform**. But since my hough algorithm was not elegant as them the square detecting algorithm of mine is a simplified version. I don't create a window and look all of the image. \n",
    "The mathematics are still more or less same except for some +- signs i needed to change because of my algorithm implementation.\n",
    "\n",
    "I find horizontal and vertical hough lines seperatly since in most of the images only horizontal lines makes the certain threshold and assigned as lines. After that i try to find pairs that are paralel by these conditions:\n",
    "$$ ∆θ = |θi − θj | < Tθ $$\n",
    "$$ ∆ρ = |ρi + ρj | < Tρ $$ \n",
    "If they met these conditions then i find the peak these lines create with formula:\n",
    "$$ αk = (θi + θj)/2 $$ \n",
    "$$ ξk = |ρi − ρj |/2. $$\n",
    "After that i to match vertical and horizontal peaks that are orthogonal with some threshold. A rectangle is then detected if:\n",
    "$$ ∆α = ||αk − αl| − 90◦| < Tα $$\n",
    "Because there are a lot of rectangles these lines can create i find the rectangle that is more suitible with the formula:\n",
    "\n",
    "$$\n",
    "E(P_k, P_l) = \\sqrt{a (\\Delta\\theta_k^2 + \\Delta\\theta_l^2 + \\Delta\\alpha^2) + b (\\Delta\\rho_k^2 + \\Delta\\rho_l^2)}\n",
    "$$\n",
    "Then i get the rectangle with least error rate. \n",
    "Note: all formulas are taken from the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97964958-2b76-4b1d-957b-af5771e784dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pairs(lines, threshold_rho = 20, threshold_theta = 0.15):\n",
    "    pairs = []\n",
    "    for i in range(len(lines)-1):\n",
    "        for j in range(i+1,len(lines)):\n",
    "            if np.abs(lines[i][0] - lines[j][0]) > threshold_rho \\\n",
    "            and np.abs(lines[i][1] - lines[j][1]) < threshold_theta:\n",
    "                pairs.append([lines[i][:2],lines[j][:2]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e30cf752-51a6-46e1-928a-77076a02732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(pairs):\n",
    "    peaks = []\n",
    "    for pair in pairs:\n",
    "        theta_i = pair[0][1]\n",
    "        theta_j = pair[1][1]\n",
    "        \n",
    "        rho_i = pair[0][0]\n",
    "        rho_j = pair[1][0]\n",
    "        \n",
    "        delta_theta = np.abs(theta_i - theta_j)\n",
    "        delta_rho = np.abs(rho_i + rho_j)\n",
    "        \n",
    "        alpha_k = 0.5 * (theta_i + theta_j)\n",
    "        xi_k = 0.5 * np.abs(rho_i + rho_j)\n",
    "        xi_k_org = 0.5 * np.abs(rho_i - rho_j)\n",
    "        peaks.append([xi_k, alpha_k, delta_rho, delta_theta,xi_k_org])\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51505dc3-63c3-41c4-8685-de20bdf3ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rectangle(horizontal_peaks, vertical_peaks, threshold, a=1,b=4):\n",
    "    rectangle = []\n",
    "    error = 999999\n",
    "    for h in range(len(horizontal_peaks)):\n",
    "        for v in range(len(vertical_peaks)):\n",
    "            alpha = np.abs(np.abs(horizontal_peaks[h][1] - vertical_peaks[v][1]) - np.deg2rad(90))\n",
    "            if  alpha < np.deg2rad(threshold):\n",
    "                error_current =  np.sqrt((a * (np.square(horizontal_peaks[h][3]) + np.square(vertical_peaks[v][3]) + np.square(alpha))) + \\\n",
    "                (b * (np.square(horizontal_peaks[h][2]) + np.square(vertical_peaks[v][2]))))\n",
    "                if error_current < error:\n",
    "                    rectangle =[horizontal_peaks[h][0], horizontal_peaks[h][1], vertical_peaks[v][0], vertical_peaks[v][1], horizontal_peaks[h][4], vertical_peaks[v][4]]\n",
    "    return rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fededa30-63cc-4f3f-848e-cf0e39575eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection(line1, line2):\n",
    "    x1, y1 = line1[0]\n",
    "    x2, y2 = line1[1]\n",
    "    x3, y3 = line2[0]\n",
    "    x4, y4 = line2[1]\n",
    "    \n",
    "    # we know lines are not parallel so denominator is never 0\n",
    "    denominator = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "    \n",
    "    # calculate intersection point\n",
    "    intersection_x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    intersection_y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    \n",
    "    return intersection_x, intersection_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab0895e-f4b6-4a08-a8ad-303657fa2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, center, orientation, width, height, color=(0, 255, 0), thickness=2):\n",
    "    # calculate the vertices of the rectangle\n",
    "    angle_rad = np.deg2rad(orientation)\n",
    "    cos_angle = np.cos(angle_rad)\n",
    "    sin_angle = np.sin(angle_rad)\n",
    "\n",
    "    half_width = width / 2\n",
    "    half_height = height / 2\n",
    "\n",
    "    # calculate the corners of the rectangle\n",
    "    corner1 = (int(center[0] - half_width * cos_angle - half_height * sin_angle),\n",
    "               int(center[1] - half_width * sin_angle + half_height * cos_angle))\n",
    "    corner2 = (int(center[0] + half_width * cos_angle - half_height * sin_angle),\n",
    "               int(center[1] + half_width * sin_angle + half_height * cos_angle))\n",
    "    corner3 = (int(center[0] + half_width * cos_angle + half_height * sin_angle),\n",
    "               int(center[1] + half_width * sin_angle - half_height * cos_angle))\n",
    "    corner4 = (int(center[0] - half_width * cos_angle + half_height * sin_angle),\n",
    "               int(center[1] - half_width * sin_angle - half_height * cos_angle))\n",
    "\n",
    "    # Draw the rectangle\n",
    "    cv2.line(image, corner1, corner2, color, thickness)\n",
    "    cv2.line(image, corner2, corner3, color, thickness)\n",
    "    cv2.line(image, corner3, corner4, color, thickness)\n",
    "    cv2.line(image, corner4, corner1, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78cd1596-792f-4f35-83be-a492f0296fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image):\n",
    "    segmented_image = image.copy()\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "    thresh = threshold_otsu(gray_image)\n",
    "    binary_mask = gray_image > thresh\n",
    "    segments = slic(image, n_segments=50, compactness=10)\n",
    "    segmentation_map = mark_boundaries(segmented_image, segments)\n",
    "    return segmentation_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a19d46-2584-49e2-8322-99303f474d7b",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cef54df-c1e0-4db1-a933-9746515b7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            # Read the image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "            else:\n",
    "                print(\"Unable to read image:\", img_path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a61eae-ae52-498c-aa7f-9dc9a6afd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_plate(image_original, method = \"canny\"):\n",
    "    result_image = image_original.copy()\n",
    "    # transforming to grayscale for computations\n",
    "    image = cv2.cvtColor(image_original, cv2.COLOR_BGR2GRAY)  \n",
    "    if method == \"canny\":\n",
    "        edge_image = canny_edge_detection(image)\n",
    "        # find hough lines\n",
    "        horizontal_lines_1 = hough_lines(edge_image,edge_threshold=200, line_threshold_min=80,theta_min=0, theta_max=20,num_of_lines = 8)\n",
    "        horizontal_lines_2 = hough_lines(edge_image,edge_threshold=200, line_threshold_min=80,theta_min=150, theta_max=180,num_of_lines = 8)\n",
    "        horizontal_lines = horizontal_lines_1 + horizontal_lines_2\n",
    "        vertical_lines = hough_lines(edge_image,edge_threshold=90, line_threshold_min=25, theta_min = 80, theta_max = 100,num_of_lines = 15)\n",
    "    elif method == \"sobel\":\n",
    "        edge_image = sobel_filter(image)[0]\n",
    "        # find hough lines\n",
    "        horizontal_lines_1 = hough_lines(edge_image,edge_threshold=100, line_threshold_min=80,theta_min=0, theta_max=20,num_of_lines = 15)\n",
    "        horizontal_lines_2 = hough_lines(edge_image,edge_threshold=100, line_threshold_min=80,theta_min=150, theta_max=180,num_of_lines = 15)\n",
    "        horizontal_lines = horizontal_lines_1 + horizontal_lines_2\n",
    "        vertical_lines = hough_lines(edge_image,edge_threshold=60, line_threshold_min=25, theta_min = 80, theta_max = 100,num_of_lines = 15)\n",
    "        \n",
    "    # draw lines to hough image\n",
    "    hough_image = image.copy()\n",
    "    hough_image = draw_hough_lines(horizontal_lines, hough_image)\n",
    "    hough_image = draw_hough_lines(vertical_lines, hough_image)\n",
    "    # find pairs from lines\n",
    "    vertical_pairs = find_pairs(vertical_lines)\n",
    "    horizontal_pairs = find_pairs(horizontal_lines)\n",
    "    # find peaks from pairs\n",
    "    vertical_peaks = find_peaks(vertical_pairs)\n",
    "    horizontal_peaks = find_peaks(horizontal_pairs)\n",
    "    # find rectangle from peaks\n",
    "    rectangle = detect_rectangle(horizontal_peaks, vertical_peaks, 8)\n",
    "    # find the center of rectangle if there's a rectangle\n",
    "    if len(rectangle) == 6:\n",
    "        pt1h, pt2h = hough_to_cartesian(rectangle[0], rectangle[1])\n",
    "        pt1v, pt2v = hough_to_cartesian(rectangle[2], rectangle[3])\n",
    "        line1 = (pt1h, pt2h)\n",
    "        line2 = (pt1v, pt2v)\n",
    "        center = find_intersection(line1, line2) \n",
    "        orientation = rectangle[1]  \n",
    "        width = 2 * rectangle[5]\n",
    "        height = 2 * rectangle[4]  \n",
    "        # draw the rectangle on the image\n",
    "        draw_rectangle(result_image, center, orientation, width, height)\n",
    "    return result_image, edge_image, hough_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3e6ae2-dc6d-446b-b915-e6b704b65d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(original_image):\n",
    "    segmented_image = segment_image(original_image)\n",
    "    result_image_sobel, edge_image_sobel, hough_image_sobel = detect_plate(original_image,method=\"sobel\")\n",
    "    result_image_canny, edge_image_canny, hough_image_canny = detect_plate(original_image,method=\"canny\")\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 4))\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(original_image)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(edge_image_sobel,cmap='gray')\n",
    "    ax[1].set_title(\"Edge Image Sobel\")\n",
    "    ax[2].imshow(hough_image_sobel, cmap='gray')\n",
    "    ax[2].set_title(\"Hough Lines Sobel\")\n",
    "    ax[3].imshow(result_image_sobel)\n",
    "    ax[3].set_title(\"Result Image Sobel\")\n",
    "    ax[4].imshow(segmented_image)\n",
    "    ax[4].set_title(\"Segmentation Map \")\n",
    "    ax[5].imshow(edge_image_canny, cmap='gray')\n",
    "    ax[5].set_title(\"Edge Image Canny\")\n",
    "    ax[6].imshow(hough_image_canny, cmap='gray')\n",
    "    ax[6].set_title(\"Hough Lines Canny\")\n",
    "    ax[7].imshow(result_image_canny)\n",
    "    ax[7].set_title(\"Result Image Canny\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3128d918-e77e-4c0e-8c44-c8d374ea3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"dataset\"\n",
    "images = read_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add18fe0-3714-4ec3-b552-7baf2913ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    visualize(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671f70e-839e-44f6-b064-b3cdb8b950d0",
   "metadata": {},
   "source": [
    "## Sobel vs Canny\n",
    "The Sobel algorithm tends to blur edges, whereas the Canny algorithm generates a clear edge map. Consequently, when using Sobel, we typically need to set a much lower edge threshold for Hough transform to detect lines effectively. However, Sobel tends to introduce more nuanced edges, leading to increased noise that can hinder Hough's performance.\n",
    "\n",
    "Conversely, Canny blurs the image prior to edge detection, resulting in sharper edges. This makes it easier for the Hough algorithm to detect lines from well-defined edges. However, this approach encounters challenges when dealing with car structures, particularly the front part, which often consists of numerous lines. Consequently, the lines defining the number plate may not always be adequately detected for reliable rectangle detection.\n",
    "\n",
    "Overall, while Canny provides clearer edges for Hough transform, it may struggle with complex structures like cars due to the multitude of lines involved, especially in the front area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c52bd1-7c09-4906-a5d9-ad44fc3f7b8c",
   "metadata": {},
   "source": [
    "## The performance of plate detection\n",
    "\n",
    "In general, relying solely on the raw Hough implementation with a square algorithm proves insufficient for plate detection. Factors such as the presence of other squares in the vicinity or the small size of the plate relative to the overall image pose significant challenges. Moreover, the dataset comprises plates captured at various angles and with different designs, making it impractical to develop a single model that performs optimally across all scenarios.\n",
    "\n",
    "Although I could enhance the algorithm by incorporating features like color detection or implementing a windowing approach to focus specifically on the plate area, I refrained from doing so as the assignment aimed to evaluate the efficacy of the Hough transform alone.\n",
    "\n",
    "Recognizing the limitations of the Hough method for plate detection, further refinement or the adoption of additional techniques may be necessary to achieve satisfactory results, especially given the diverse nature of the dataset and the inherent complexities of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891896f1-912e-43e1-bae4-b06bee05912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want to save the images use this function\n",
    "def save_image(original_image, file_name):\n",
    "    result_image_canny, edge_image_canny, hough_image_canny = detect_plate(original_image,method=\"canny\")\n",
    "    filename = f\"{file_name}.png\"\n",
    "    cv2.imwrite(filename, result_image_canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d3ccb-2afa-4c88-a127-12222ea0bbac",
   "metadata": {},
   "source": [
    "I have achieved successful results with the algorithm, particularly when the image contains only a car plate. In cases where the angle or orientation varies, I've observed that with some adjustments to the threshold, the algorithm is still able to accurately detect the plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e2df2-bd2d-44e7-947b-2fc74006d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"Cars33.png\"\n",
    "image_original = cv2.imread(IMAGE_PATH)\n",
    "file_name = \"Cars33_result.png\"\n",
    "save_image(image_original,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e889c-c4dd-47bf-b5ce-58c147c6d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"Cars102.png\"\n",
    "image_original = cv2.imread(IMAGE_PATH)\n",
    "file_name = \"Cars102_result.png\"\n",
    "save_image(image_original,file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
